# Summary Post

*by Fabian Narel - Sunday, 20 April 2025, 3:32 AM*

Large Language Models (LLMs) like GPT-3 have transformed the writing landscape, offering fluent and efficient text generation. My initial post highlighted how their impact varies depending on the context—from helpful drafting tools in low-risk scenarios to potentially problematic agents in high-risk domains such as journalism or creative writing.

Peers expanded on these ideas with insightful contributions. One peer warned about the erosion of users' own communication skills due to over-reliance on AI for routine tasks (Hutson, 2021). Another highlighted the political and ethical dangers of AI-generated content influencing public opinion, as LLMs can sound convincingly accurate even when they are factually wrong (Coeckelbergh, 2025; Goetz et al., 2023). This supports the need for careful supervision and responsible deployment.

A useful framework was also introduced: using AI either as a drafting assistant or as a feedback tool (Kapuściński, 2025; Thornburn, 2024). This approach allows humans to remain in control while still benefiting from AI's efficiency. The dual-use strategy reflects the broader theme across the posts—that AI is a collaborator, not a replacement.

Across all contributions, the consensus is clear: while LLMs offer undeniable advantages in terms of speed and accessibility, they pose risks related to reliability, originality, and ethical integrity. Their "agreeable" tone (Goetz et al., 2023) can mask inaccuracies and reinforce confirmation bias. Used without critical thinking, they may undermine the very skills they aim to support.

## References

Coeckelbergh, M. (2025) Truth, post-truth, and democracy in the age of artificial intelligence: Epistemological and political risks of language models. AI and Society. Available from: https://doi.org/10.1007/s00148-025-00529-0 [Accessed 7 April 2025].

Goetz, L., Trengove, M., Trotsyuk, A. and Federico, C.A. (2023) Unreliable LLM bioethics assistants: Ethical and pedagogical risks. The American Journal of Bioethics, 23(10), pp.89–91. Available from: https://doi.org/10.1080/15265161.2023.2249843 [Accessed 7 April 2025].

Hutson, M. (2021) Robo-writers: the rise and risks of language-generating AI. Nature, 591(7848), pp.22–25.

Kapuściński, M. (2025) ChatGPT 4.5 – What's New? Practical Examples and Applications. TTMS. Available from: https://ttms.com/chatgpt-whats-new [Accessed 17 April 2025].

Thornburn, R. (2024) How to use AI to Generate Student Feedback. English for Asia. Available from: https://hongkongtesol.com/ai-feedback [Accessed 17 April 2025]. 